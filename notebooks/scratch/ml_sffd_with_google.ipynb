{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "import boto3\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "ss = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'msds697jonross.and.friends' # Add your bucket name\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_fire = 'sffd.csv' # select file\n",
    "obj_fire = bucket.Object(key=file_name_fire) # S3 uses key-value structure where key is your file name\n",
    "file_content_fire = obj_fire.get()[\"Body\"].read().decode(\"utf-8\") # Read the Body which is the contents of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_goo = 'google_data.csv' # select file\n",
    "obj_goo = bucket.Object(key=file_name_goo) # S3 uses key-value structure where key is your file name\n",
    "file_content_goo = obj_goo.get()[\"Body\"].read().decode(\"utf-8\") # Read the Body which is the contents of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4557045"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows (subract header and empty line at end)\n",
    "rows_fire = file_content_fire.split('\\n')\n",
    "len(rows_fire)-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32074"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows (subract empty line at end)\n",
    "rows_goo = file_content_goo.split('\\n')\n",
    "len(rows_goo)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of  columns\n",
    "column_names_fire = rows_fire[0].split(',')\n",
    "n_cols = sc.broadcast(len(column_names_fire))\n",
    "n_cols.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_type\n",
      "received_timestamp\n",
      "entry_timestamp\n",
      "dispatch_timestamp\n",
      "response_timestamp\n",
      "on_scene_timestamp\n",
      "transport_timestamp\n",
      "hospital_timestamp\n",
      "call_final_disposition\n",
      "available_timestamp\n",
      "address\n",
      "zipcode_of_incident\n",
      "battalion\n",
      "station_area\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(x for x in column_names_fire))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HazMat,2010-09-01 07:53:36+00:00,2010-09-01 07:54:46+00:00,2010-09-01 07:55:07+00:00,2010-09-01 07:55:55+00:00,,,,Other,2010-09-01 08:00:31+00:00,400 Block of HOWARD ST,94105,B03,35',\n",
       "       'Medical Incident,2014-12-21 15:40:07+00:00,2014-12-21 15:43:30+00:00,2014-12-21 15:43:57+00:00,2014-12-21 15:45:06+00:00,2014-12-21 15:48:26+00:00,,,Unable to Locate,2014-12-21 15:52:32+00:00,YORK ST/CESAR CHAVEZ ST,94110,B06,09'],\n",
       "      dtype='<U315')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly sample rows\n",
    "sz=100000\n",
    "samples_fire = np.random.choice(rows_fire[1:], size=sz, replace=False)\n",
    "samples_fire[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = [f\"0{i}\" for i in range(1,10)] +\\\n",
    "    [str(i) for i in list(range(10,27))] +\\\n",
    "    ['28','29'] +\\\n",
    "    [str(i) for i in list(range(31,45))] +\\\n",
    "    ['48','49','51']\n",
    "stations = sc.broadcast(stations)\n",
    "# stations.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fire(x):\n",
    "    if len(x.split(',')) == n_cols.value:\n",
    "        return x.split(',')[13] in stations.value\n",
    "\n",
    "def map_fire(x):\n",
    "    return ((x.split(',')[13],x.split(',')[10]), x.split(',')[:2]+[x.split(',')[5]]+[x.split(',')[11]])\n",
    "\n",
    "def map_google(x):\n",
    "    s = x.split(',')\n",
    "    try:\n",
    "        if int(s[0]) < 10:\n",
    "            s[0] = '0' + s[0]\n",
    "    except:\n",
    "        pass\n",
    "    return (tuple(s[:2]), s[2:])\n",
    "\n",
    "def map_joined(x):\n",
    "    try:\n",
    "        return list(x[0])+x[1][0]+[float(y) for y in x[1][1]]\n",
    "    except:\n",
    "        return list(x[0])+x[1][0]+[None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_fire = sc.parallelize(list(samples_fire))\\\n",
    "    .filter(filter_fire)\\\n",
    "    .map(map_fire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_google = sc.parallelize(rows_goo)\\\n",
    "    .map(map_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('35', '400 Block of HOWARD ST'),\n",
       "  ['HazMat', '2010-09-01 07:53:36+00:00', '', '94105']),\n",
       " (('09', 'YORK ST/CESAR CHAVEZ ST'),\n",
       "  ['Medical Incident',\n",
       "   '2014-12-21 15:40:07+00:00',\n",
       "   '2014-12-21 15:48:26+00:00',\n",
       "   '94110'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_fire.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('01', '0 Block of 0NB OCTAVIA OF'), ['3724', '12.883333333333333']),\n",
       " (('01', '0 Block of 101 NB OCTAVIA OF'), ['4290', '9.416666666666666'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_google.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = rdd_fire.leftOuterJoin(rdd_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('01', 'GRANT AV/POST ST'),\n",
       "  (['Medical Incident', '2001-03-19 12:09:43+00:00', '', '94108'],\n",
       "   ['1531', '6.816666666666666'])),\n",
       " (('01', 'GRANT AV/POST ST'),\n",
       "  (['Structure Fire', '2014-07-26 05:12:24+00:00', '', '94108'],\n",
       "   ['1531', '6.816666666666666']))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = joined.map(map_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['01',\n",
       "  'GRANT AV/POST ST',\n",
       "  'Medical Incident',\n",
       "  '2001-03-19 12:09:43+00:00',\n",
       "  '',\n",
       "  '94108',\n",
       "  1531.0,\n",
       "  6.816666666666666],\n",
       " ['01',\n",
       "  'GRANT AV/POST ST',\n",
       "  'Structure Fire',\n",
       "  '2014-07-26 05:12:24+00:00',\n",
       "  '',\n",
       "  '94108',\n",
       "  1531.0,\n",
       "  6.816666666666666]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1495"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows removed\n",
    "sz - rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"station_area\", StringType(), False),\n",
    "                     StructField(\"address\", StringType(), False),\n",
    "                     StructField(\"call_type\", StringType(), False),\n",
    "                     StructField(\"received_timestamp\", StringType(), False),\n",
    "                     StructField(\"on_scene_timestamp\", StringType(), False),\n",
    "                     StructField(\"zipcode_of_incident\", StringType(), False),\n",
    "                     StructField(\"distance\", FloatType(), True),\n",
    "                     StructField(\"duration\", FloatType(), True)\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ss.createDataFrame(rdd, schema) # .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_area: string (nullable = false)\n",
      " |-- address: string (nullable = false)\n",
      " |-- call_type: string (nullable = false)\n",
      " |-- received_timestamp: string (nullable = false)\n",
      " |-- on_scene_timestamp: string (nullable = false)\n",
      " |-- zipcode_of_incident: string (nullable = false)\n",
      " |-- distance: float (nullable = true)\n",
      " |-- duration: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to timestamps\n",
    "my_rows = ['received_timestamp',\n",
    "          'on_scene_timestamp']\n",
    "\n",
    "df_w_time = df\n",
    "for row in my_rows:\n",
    "    df_w_time = df_w_time.withColumn(row, to_timestamp(df[row], format = 'yyyy-MM-dd HH:mm:ss+00:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_full = df_w_time.select('station_area',\n",
    "                 'address',\n",
    "                 'call_type',\n",
    "                 'received_timestamp',\n",
    "                 'on_scene_timestamp',\n",
    "                 'zipcode_of_incident',\n",
    "                 'distance',\n",
    "                 'duration')\\\n",
    "    .withColumn(\"label\", \n",
    "                (unix_timestamp('on_scene_timestamp') - unix_timestamp('received_timestamp')) / 60)\\\n",
    "    .orderBy('received_timestamp', ascending=[0])\\\n",
    "    .na.drop(subset=[\"label\"])\\\n",
    "    .where('label != 0')\\\n",
    "    .select('station_area',\n",
    "        'call_type',\n",
    "        'zipcode_of_incident',\n",
    "        'distance',\n",
    "        'duration',\n",
    "        'label')\n",
    "\n",
    "# data_1 is the largest dataset\n",
    "# has all columns and ony removes missing google data\n",
    "data_1 = data_full.na.drop(subset=[\"distance\", \"duration\"]) # (removes about 50 rows)\n",
    "data_2 = data_1.where('distance < 8000') # approximately 5 miles (removes about 700 rows)\n",
    "data_3 = data_2.where('label < 30') # less than 30 minutes (removes about 1100 rows)\n",
    "data_4 = data_1.select('distance','duration','label') # just the duration and distance columns\n",
    "data_5 = data_4.where('distance < 8000')\n",
    "data_6 = data_5.where('label < 30')\n",
    "data_7 = data_1.where('label < 20')\n",
    "data_8 = data_4.where('label < 20')\n",
    "data_9 = data_1.where('label < 10')\n",
    "data_10 = data_4.where('label < 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+-------------------+--------+---------+------------------+\n",
      "|station_area|        call_type|zipcode_of_incident|distance| duration|             label|\n",
      "+------------+-----------------+-------------------+--------+---------+------------------+\n",
      "|          18|            Other|              94116|  1820.0| 4.483333|12.916666666666666|\n",
      "|          21| Medical Incident|              94117|  1439.0|      4.5| 6.833333333333333|\n",
      "|          11|Traffic Collision|              94110|   429.0|      1.5|               4.0|\n",
      "|          42|Traffic Collision|              94134|    92.0|     0.55|               3.0|\n",
      "|          08| Medical Incident|              94107|   906.0|4.1666665|             15.15|\n",
      "+------------+-----------------+-------------------+--------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "75309\n",
      "75250\n",
      "74510\n",
      "73357\n",
      "75250\n",
      "74510\n",
      "73357\n",
      "71507\n",
      "71507\n",
      "58061\n",
      "58061\n"
     ]
    }
   ],
   "source": [
    "data_1.show(5)\n",
    "for d in (data_full, data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8,data_9,data_10):\n",
    "    print(d.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+------------------+------------------+\n",
      "|       avg(label)|     avg(duration)|   var_samp(label)|var_samp(duration)|\n",
      "+-----------------+------------------+------------------+------------------+\n",
      "|7.900106556520394|3.9686669308964615|21.445902259004406| 6.090160642913485|\n",
      "+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_6.select(mean('label'), mean('duration'),\n",
    "             variance('label'), variance('duration')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------------+\n",
      "|distance|  duration|             label|\n",
      "+--------+----------+------------------+\n",
      "|  1820.0|  4.483333|12.916666666666666|\n",
      "|  1439.0|       4.5| 6.833333333333333|\n",
      "|   429.0|       1.5|               4.0|\n",
      "|    92.0|      0.55|               3.0|\n",
      "|   906.0| 4.1666665|             15.15|\n",
      "|  1212.0| 3.3333333|              11.8|\n",
      "|   163.0|0.96666664| 5.766666666666667|\n",
      "|  1283.0|      6.35|              5.95|\n",
      "|  1747.0| 5.9666667|              6.55|\n",
      "|  1441.0|  4.233333| 9.266666666666667|\n",
      "+--------+----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_6.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_strings(df):\n",
    "    return df.replace('','unknown')\n",
    "# dfnonas = remove_empty_strings(small_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting strings to numeric values\n",
    "def indexStringColumns(df, cols):\n",
    "    #variable newdf will be updated several times\n",
    "    newdf = df\n",
    "    \n",
    "    for c in cols:\n",
    "        #For each given colum, fits StringIndexerModel.\n",
    "        si = StringIndexer(inputCol=c, outputCol=c+\"-num\")\n",
    "        sm = si.fit(newdf)\n",
    "        #Creates a DataFame by putting the transformed values in the new colum with suffix \"-num\" \n",
    "        #and then drops the original columns.\n",
    "        #and drop the \"-num\" suffix. \n",
    "        newdf = sm.transform(newdf).drop(c)\n",
    "        newdf = newdf.withColumnRenamed(c+\"-num\", c)\n",
    "    return newdf\n",
    "\n",
    "# dfnumeric = indexStringColumns(dfnonas, [\"call_type\", \"zipcode_of_incident\", \"station_area\"])\n",
    "# dfnumeric = indexStringColumns(dfnonas, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncodeColumns(df, cols):\n",
    "    newdf = df\n",
    "    for c in cols:\n",
    "        #For each given colum, create OneHotEncoder. \n",
    "        #dropLast : Whether to drop the last category in the encoded vector (default: true)\n",
    "        onehotenc = OneHotEncoder(inputCol=c, outputCol=c+\"-onehot\", dropLast=False)\n",
    "        #Creates a DataFame by putting the transformed values in the new colum with suffix \"-onehot\" \n",
    "        #and then drops the original columns.\n",
    "        #and drop the \"-onehot\" suffix. \n",
    "        newdf = onehotenc.transform(newdf).drop(c)\n",
    "        newdf = newdf.withColumnRenamed(c+\"-onehot\", c)\n",
    "    return newdf\n",
    "\n",
    "# dfhot = oneHotEncodeColumns(dfnumeric, [\"call_type\", \"zipcode_of_incident\", \"station_area\"])\n",
    "# dfhot = oneHotEncodeColumns(dfnumeric, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df, cat_cols, hot_cols):\n",
    "    dfnonas = remove_empty_strings(df)\n",
    "    dfnumeric = indexStringColumns(dfnonas, cat_cols)\n",
    "    dfhot = oneHotEncodeColumns(dfnumeric, hot_cols)\n",
    "    return dfhot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = process(data_10,\n",
    "                         cat_cols=[],\n",
    "                         hot_cols=[])\n",
    "\n",
    "# processed_data = process(data_9,\n",
    "#                          cat_cols=[\"call_type\", \"zipcode_of_incident\", \"station_area\"],\n",
    "#                          hot_cols=[\"call_type\", \"zipcode_of_incident\", \"station_area\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test data.\n",
    "sets = processed_data.randomSplit([0.8, 0.2])\n",
    "train = sets[0] # .cache()\n",
    "test = sets[1] # .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipelines\n",
    "va = VectorAssembler(outputCol=\"features\",\n",
    "                     inputCols=[x for x in processed_data.columns if x != 'label'])\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "lr = LinearRegression()\n",
    "\n",
    "pipeline_lr = Pipeline(stages=[va,lr])\n",
    "pipeline_rf = Pipeline(stages=[va,rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit models\n",
    "lr_fitted = pipeline_lr.fit(train)\n",
    "rf_fitted = pipeline_rf.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results - careful about re-running cells\n",
    "In each section, first cell is results on all columns and second cell uses just `distance` and `duration`. Once we start restricting response times, we see that the metrics are consistently better when we have use all of the columns and not just these two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model results\n",
    "def evaluate_regression(fitted_model, test_set):\n",
    "    test_pred = fitted_model.transform(test_set)\n",
    "    r2_ev = RegressionEvaluator(metricName='r2')\n",
    "    rmse_ev = RegressionEvaluator(metricName='rmse')\n",
    "    mae_ev = RegressionEvaluator(metricName='mae')\n",
    "    r2 = r2_ev.evaluate(test_pred)\n",
    "    rmse = rmse_ev.evaluate(test_pred)\n",
    "    mae = mae_ev.evaluate(test_pred)\n",
    "    return (r2,rmse,mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data\n",
    "\n",
    "Random Forest has much lower RMSE, other metrics about the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "R^2:  0.024123781896566276\n",
      "RMSE: 16.91553255119037\n",
      "MAE:  4.1326953987440325\n",
      "Random Forest\n",
      "R^2:  0.007411846391023991\n",
      "RMSE: 8.521495726129338\n",
      "MAE:  4.15831882230389\n"
     ]
    }
   ],
   "source": [
    "# data_1\n",
    "ev_lr = evaluate_regression(fitted_model=lr_fitted, test_set=test)\n",
    "print(f\"Linear Regression:\\nR^2:  {ev_lr[0]}\\nRMSE: {ev_lr[1]}\\nMAE:  {ev_lr[2]}\")\n",
    "ev_rf = evaluate_regression(fitted_model=rf_fitted, test_set=test)\n",
    "print(f\"Random Forest\\nR^2:  {ev_rf[0]}\\nRMSE: {ev_rf[1]}\\nMAE:  {ev_rf[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "R^2:  0.0025279094655130674\n",
      "RMSE: 15.984160416015817\n",
      "MAE:  4.4516522225800355\n",
      "Random Forest\n",
      "R^2:  0.002132135890805853\n",
      "RMSE: 11.290663267309872\n",
      "MAE:  4.2393099674474914\n"
     ]
    }
   ],
   "source": [
    "# data_4\n",
    "ev_lr = evaluate_regression(fitted_model=lr_fitted, test_set=test)\n",
    "print(f\"Linear Regression:\\nR^2:  {ev_lr[0]}\\nRMSE: {ev_lr[1]}\\nMAE:  {ev_lr[2]}\")\n",
    "ev_rf = evaluate_regression(fitted_model=rf_fitted, test_set=test)\n",
    "print(f\"Random Forest\\nR^2:  {ev_rf[0]}\\nRMSE: {ev_rf[1]}\\nMAE:  {ev_rf[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance under 5 miles\n",
    "\n",
    "Random Forest has larger RMSE when using just `distance` and `duration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "R^2:  0.011747170232487392\n",
      "RMSE: 18.237697208031083\n",
      "MAE:  4.138500431421881\n",
      "Random Forest\n",
      "R^2:  0.07787912148991272\n",
      "RMSE: 11.024637278044311\n",
      "MAE:  4.17742435452288\n"
     ]
    }
   ],
   "source": [
    "# data_2\n",
    "ev_lr = evaluate_regression(fitted_model=lr_fitted, test_set=test)\n",
    "print(f\"Linear Regression:\\nR^2:  {ev_lr[0]}\\nRMSE: {ev_lr[1]}\\nMAE:  {ev_lr[2]}\")\n",
    "ev_rf = evaluate_regression(fitted_model=rf_fitted, test_set=test)\n",
    "print(f\"Random Forest\\nR^2:  {ev_rf[0]}\\nRMSE: {ev_rf[1]}\\nMAE:  {ev_rf[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "R^2:  0.004887448693409291\n",
      "RMSE: 9.302058481339335\n",
      "MAE:  4.339269175512891\n",
      "Random Forest\n",
      "R^2:  0.003757202013706773\n",
      "RMSE: 12.16717568442183\n",
      "MAE:  4.267489319780205\n"
     ]
    }
   ],
   "source": [
    "# data_5\n",
    "ev_lr = evaluate_regression(fitted_model=lr_fitted, test_set=test)\n",
    "print(f\"Linear Regression:\\nR^2:  {ev_lr[0]}\\nRMSE: {ev_lr[1]}\\nMAE:  {ev_lr[2]}\")\n",
    "ev_rf = evaluate_regression(fitted_model=rf_fitted, test_set=test)\n",
    "print(f\"Random Forest\\nR^2:  {ev_rf[0]}\\nRMSE: {ev_rf[1]}\\nMAE:  {ev_rf[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response time under 30 minutes and distance under 5 miles\n",
    "Linear regression on all columns shows best results so far, but rf and lr are about even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "R^2:  0.05760830583437737\n",
      "RMSE: 4.448589286539655\n",
      "MAE:  3.157774939960122\n",
      "Random Forest\n",
      "R^2:  0.05139482839197307\n",
      "RMSE: 4.570550521980881\n",
      "MAE:  3.199242685090251\n"
     ]
    }
   ],
   "source": [
    "# data_3\n",
    "ev_lr = evaluate_regression(fitted_model=lr_fitted, test_set=test)\n",
    "print(f\"Linear Regression:\\nR^2:  {ev_lr[0]}\\nRMSE: {ev_lr[1]}\\nMAE:  {ev_lr[2]}\")\n",
    "ev_rf = evaluate_regression(fitted_model=rf_fitted, test_set=test)\n",
    "print(f\"Random Forest\\nR^2:  {ev_rf[0]}\\nRMSE: {ev_rf[1]}\\nMAE:  {ev_rf[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "R^2:  0.007980575876808005\n",
      "RMSE: 4.645194347474092\n",
      "MAE:  3.284769959525284\n",
      "Random Forest\n",
      "R^2:  0.012756496234489823\n",
      "RMSE: 4.5969485899603635\n",
      "MAE:  3.284296656386548\n"
     ]
    }
   ],
   "source": [
    "# data_6\n",
    "ev_lr = evaluate_regression(fitted_model=lr_fitted, test_set=test)\n",
    "print(f\"Linear Regression:\\nR^2:  {ev_lr[0]}\\nRMSE: {ev_lr[1]}\\nMAE:  {ev_lr[2]}\")\n",
    "ev_rf = evaluate_regression(fitted_model=rf_fitted, test_set=test)\n",
    "print(f\"Random Forest\\nR^2:  {ev_rf[0]}\\nRMSE: {ev_rf[1]}\\nMAE:  {ev_rf[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response time under 20 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "R^2:  0.07058101144354822\n",
      "RMSE: 3.4348941696083926\n",
      "MAE:  2.59477181595019\n",
      "Random Forest\n",
      "R^2:  0.0636771025288424\n",
      "RMSE: 3.475151985473244\n",
      "MAE:  2.6325462510540683\n"
     ]
    }
   ],
   "source": [
    "# data_7\n",
    "ev_lr = evaluate_regression(fitted_model=lr_fitted, test_set=test)\n",
    "print(f\"Linear Regression:\\nR^2:  {ev_lr[0]}\\nRMSE: {ev_lr[1]}\\nMAE:  {ev_lr[2]}\")\n",
    "ev_rf = evaluate_regression(fitted_model=rf_fitted, test_set=test)\n",
    "print(f\"Random Forest\\nR^2:  {ev_rf[0]}\\nRMSE: {ev_rf[1]}\\nMAE:  {ev_rf[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "R^2:  0.005668059927685931\n",
      "RMSE: 3.5687820031549062\n",
      "MAE:  2.706931626315683\n",
      "Random Forest\n",
      "R^2:  0.01587843454160398\n",
      "RMSE: 3.511942347124428\n",
      "MAE:  2.708119644041678\n"
     ]
    }
   ],
   "source": [
    "# data_8\n",
    "ev_lr = evaluate_regression(fitted_model=lr_fitted, test_set=test)\n",
    "print(f\"Linear Regression:\\nR^2:  {ev_lr[0]}\\nRMSE: {ev_lr[1]}\\nMAE:  {ev_lr[2]}\")\n",
    "ev_rf = evaluate_regression(fitted_model=rf_fitted, test_set=test)\n",
    "print(f\"Random Forest\\nR^2:  {ev_rf[0]}\\nRMSE: {ev_rf[1]}\\nMAE:  {ev_rf[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response time under 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "R^2:  0.07534076155725988\n",
      "RMSE: 1.8215848776812464\n",
      "MAE:  1.462095511225529\n",
      "Random Forest\n",
      "R^2:  0.06409058397892797\n",
      "RMSE: 1.8136400902373682\n",
      "MAE:  1.4644012341860397\n"
     ]
    }
   ],
   "source": [
    "# data_9\n",
    "ev_lr = evaluate_regression(fitted_model=lr_fitted, test_set=test)\n",
    "print(f\"Linear Regression:\\nR^2:  {ev_lr[0]}\\nRMSE: {ev_lr[1]}\\nMAE:  {ev_lr[2]}\")\n",
    "ev_rf = evaluate_regression(fitted_model=rf_fitted, test_set=test)\n",
    "print(f\"Random Forest\\nR^2:  {ev_rf[0]}\\nRMSE: {ev_rf[1]}\\nMAE:  {ev_rf[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "R^2:  0.004414109096016583\n",
      "RMSE: 1.8919566430244967\n",
      "MAE:  1.5052075248679457\n",
      "Random Forest\n",
      "R^2:  0.02789106584729928\n",
      "RMSE: 1.8336034161065586\n",
      "MAE:  1.5060200355496516\n"
     ]
    }
   ],
   "source": [
    "# data_10\n",
    "ev_lr = evaluate_regression(fitted_model=lr_fitted, test_set=test)\n",
    "print(f\"Linear Regression:\\nR^2:  {ev_lr[0]}\\nRMSE: {ev_lr[1]}\\nMAE:  {ev_lr[2]}\")\n",
    "ev_rf = evaluate_regression(fitted_model=rf_fitted, test_set=test)\n",
    "print(f\"Random Forest\\nR^2:  {ev_rf[0]}\\nRMSE: {ev_rf[1]}\\nMAE:  {ev_rf[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
